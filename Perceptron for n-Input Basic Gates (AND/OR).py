{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4sugseByzZK4nvob9peuT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandip988/ANN_021_348/blob/main/Perceptron%20for%20n-Input%20Basic%20Gates%20(AND/OR).py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8FJ152D945i",
        "outputId": "444e2a38-f8f6-4e5d-e9e9-442d397c7368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Testing 3-input AND gate ===\n",
            "\n",
            "Initial weights: [0.37454012 0.95071431 0.73199394], Initial bias: 0.5987\n",
            "Epoch 1: weights = [0.07454012 0.65071431 0.43199394], bias = -0.1013, errors = 7\n",
            "Epoch 2: weights = [-0.02545988  0.35071431  0.23199394], bias = -0.5013, errors = 4\n",
            "Epoch 3: weights = [0.07454012 0.35071431 0.23199394], bias = -0.5013, errors = 2\n",
            "Epoch 4: weights = [0.17454012 0.35071431 0.23199394], bias = -0.5013, errors = 2\n",
            "Epoch 5: weights = [0.27454012 0.35071431 0.23199394], bias = -0.5013, errors = 2\n",
            "Epoch 6: weights = [0.27454012 0.25071431 0.13199394], bias = -0.6013, errors = 1\n",
            "Epoch 7: weights = [0.27454012 0.25071431 0.13199394], bias = -0.6013, errors = 0\n",
            "Converged after 7 epochs\n",
            "\n",
            "Final 3-input AND gate weights: [0.27454012 0.25071431 0.13199394]\n",
            "Final 3-input AND gate bias: -0.6013\n",
            "AND gate accuracy: 100.00%\n",
            "\n",
            "=== Testing 3-input OR gate ===\n",
            "\n",
            "Initial weights: [0.15601864 0.15599452 0.05808361], Initial bias: 0.8662\n",
            "Epoch 1: weights = [0.15601864 0.15599452 0.05808361], bias = 0.7662, errors = 1\n",
            "Epoch 2: weights = [0.15601864 0.15599452 0.05808361], bias = 0.6662, errors = 1\n",
            "Epoch 3: weights = [0.15601864 0.15599452 0.05808361], bias = 0.5662, errors = 1\n",
            "Epoch 4: weights = [0.15601864 0.15599452 0.05808361], bias = 0.4662, errors = 1\n",
            "Epoch 5: weights = [0.15601864 0.15599452 0.05808361], bias = 0.3662, errors = 1\n",
            "Epoch 6: weights = [0.15601864 0.15599452 0.05808361], bias = 0.2662, errors = 1\n",
            "Epoch 7: weights = [0.15601864 0.15599452 0.05808361], bias = 0.1662, errors = 1\n",
            "Epoch 8: weights = [0.15601864 0.15599452 0.05808361], bias = 0.0662, errors = 1\n",
            "Epoch 9: weights = [0.15601864 0.15599452 0.05808361], bias = -0.0338, errors = 1\n",
            "Epoch 10: weights = [0.15601864 0.15599452 0.05808361], bias = -0.0338, errors = 0\n",
            "Converged after 10 epochs\n",
            "\n",
            "Final 3-input OR gate weights: [0.15601864 0.15599452 0.05808361]\n",
            "Final 3-input OR gate bias: -0.0338\n",
            "OR gate accuracy: 100.00%\n",
            "\n",
            "=== Testing 4-input AND gate ===\n",
            "\n",
            "Initial weights: [0.60111501 0.70807258 0.02058449 0.96990985], Initial bias: 0.8324\n",
            "Epoch 1: weights = [ 0.20111501  0.20807258 -0.37941551  0.36990985], bias = -0.3676, errors = 14\n",
            "Epoch 2: weights = [ 0.30111501  0.20807258 -0.27941551  0.26990985], bias = -0.4676, errors = 3\n",
            "Epoch 3: weights = [ 0.30111501  0.10807258 -0.17941551  0.16990985], bias = -0.5676, errors = 3\n",
            "Epoch 4: weights = [ 0.30111501  0.10807258 -0.07941551  0.16990985], bias = -0.5676, errors = 2\n",
            "Epoch 5: weights = [0.30111501 0.10807258 0.02058449 0.16990985], bias = -0.5676, errors = 2\n",
            "Epoch 6: weights = [0.30111501 0.10807258 0.12058449 0.16990985], bias = -0.5676, errors = 2\n",
            "Epoch 7: weights = [0.30111501 0.20807258 0.12058449 0.16990985], bias = -0.5676, errors = 2\n",
            "Epoch 8: weights = [0.30111501 0.30807258 0.12058449 0.16990985], bias = -0.5676, errors = 2\n",
            "Epoch 9: weights = [0.40111501 0.30807258 0.12058449 0.16990985], bias = -0.5676, errors = 2\n",
            "Epoch 10: weights = [0.40111501 0.20807258 0.12058449 0.06990985], bias = -0.6676, errors = 3\n",
            "Epoch 11: weights = [0.40111501 0.20807258 0.22058449 0.06990985], bias = -0.6676, errors = 2\n",
            "Epoch 12: weights = [0.40111501 0.30807258 0.22058449 0.06990985], bias = -0.6676, errors = 2\n",
            "Epoch 13: weights = [0.40111501 0.40807258 0.22058449 0.06990985], bias = -0.6676, errors = 2\n",
            "Epoch 14: weights = [0.40111501 0.30807258 0.12058449 0.06990985], bias = -0.7676, errors = 3\n",
            "Epoch 15: weights = [0.40111501 0.30807258 0.22058449 0.06990985], bias = -0.7676, errors = 2\n",
            "Epoch 16: weights = [0.40111501 0.30807258 0.32058449 0.06990985], bias = -0.7676, errors = 2\n",
            "Epoch 17: weights = [0.40111501 0.40807258 0.32058449 0.06990985], bias = -0.7676, errors = 2\n",
            "Epoch 18: weights = [0.40111501 0.30807258 0.22058449 0.06990985], bias = -0.8676, errors = 3\n",
            "Epoch 19: weights = [0.40111501 0.30807258 0.22058449 0.16990985], bias = -0.8676, errors = 2\n",
            "Epoch 20: weights = [0.40111501 0.30807258 0.32058449 0.16990985], bias = -0.8676, errors = 2\n",
            "Epoch 21: weights = [0.40111501 0.40807258 0.32058449 0.16990985], bias = -0.8676, errors = 2\n",
            "Epoch 22: weights = [0.40111501 0.30807258 0.22058449 0.06990985], bias = -0.9676, errors = 1\n",
            "Epoch 23: weights = [0.40111501 0.30807258 0.22058449 0.06990985], bias = -0.9676, errors = 0\n",
            "Converged after 23 epochs\n",
            "\n",
            "Final 4-input AND gate weights: [0.40111501 0.30807258 0.22058449 0.06990985]\n",
            "Final 4-input AND gate bias: -0.9676\n",
            "AND gate accuracy: 100.00%\n",
            "\n",
            "=== Testing 4-input OR gate ===\n",
            "\n",
            "Initial weights: [0.21233911 0.18182497 0.18340451 0.30424224], Initial bias: 0.5248\n",
            "Epoch 1: weights = [0.21233911 0.18182497 0.18340451 0.30424224], bias = 0.4248, errors = 1\n",
            "Epoch 2: weights = [0.21233911 0.18182497 0.18340451 0.30424224], bias = 0.3248, errors = 1\n",
            "Epoch 3: weights = [0.21233911 0.18182497 0.18340451 0.30424224], bias = 0.2248, errors = 1\n",
            "Epoch 4: weights = [0.21233911 0.18182497 0.18340451 0.30424224], bias = 0.1248, errors = 1\n",
            "Epoch 5: weights = [0.21233911 0.18182497 0.18340451 0.30424224], bias = 0.0248, errors = 1\n",
            "Epoch 6: weights = [0.21233911 0.18182497 0.18340451 0.30424224], bias = -0.0752, errors = 1\n",
            "Epoch 7: weights = [0.21233911 0.18182497 0.18340451 0.30424224], bias = -0.0752, errors = 0\n",
            "Converged after 7 epochs\n",
            "\n",
            "Final 4-input OR gate weights: [0.21233911 0.18182497 0.18340451 0.30424224]\n",
            "Final 4-input OR gate bias: -0.0752\n",
            "OR gate accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "# Step activation function\n",
        "def step_function(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "# Generate truth table for n inputs\n",
        "def generate_truth_table(n):\n",
        "    # Generate all possible combinations of n binary inputs\n",
        "    X = np.array(list(itertools.product([0, 1], repeat=n)))\n",
        "    # AND gate: 1 only when all inputs are 1\n",
        "    y_and = np.array([1 if np.all(x == 1) else 0 for x in X])\n",
        "    # OR gate: 1 if at least one input is 1\n",
        "    y_or = np.array([1 if np.any(x == 1) else 0 for x in X])\n",
        "    return X, y_and, y_or\n",
        "\n",
        "# Perceptron class\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size, learning_rate=0.1):\n",
        "        self.weights = np.random.rand(input_size)  # Random initial weights\n",
        "        self.bias = np.random.rand()  # Random initial bias\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def predict(self, X):\n",
        "        return step_function(np.dot(X, self.weights) + self.bias)\n",
        "\n",
        "    def train(self, X, y, max_epochs=100):\n",
        "        print(f\"\\nInitial weights: {self.weights}, Initial bias: {self.bias:.4f}\")\n",
        "        for epoch in range(max_epochs):\n",
        "            errors = 0\n",
        "            for i in range(len(X)):\n",
        "                prediction = self.predict(X[i])\n",
        "                error = y[i] - prediction\n",
        "                if error != 0:\n",
        "                    errors += 1\n",
        "                    # Update weights and bias\n",
        "                    self.weights += self.learning_rate * error * X[i]\n",
        "                    self.bias += self.learning_rate * error\n",
        "            # Print weights and bias after each epoch\n",
        "            print(f\"Epoch {epoch+1}: weights = {self.weights}, bias = {self.bias:.4f}, errors = {errors}\")\n",
        "            # Check for convergence (no errors)\n",
        "            if errors == 0:\n",
        "                print(f\"Converged after {epoch+1} epochs\")\n",
        "                break\n",
        "        return errors == 0\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        correct = 0\n",
        "        for i in range(len(X)):\n",
        "            prediction = self.predict(X[i])\n",
        "            if prediction == y[i]:\n",
        "                correct += 1\n",
        "        return correct / len(X)\n",
        "\n",
        "# Function to test Perceptron for a given n\n",
        "def test_perceptron(n):\n",
        "    # Generate truth table\n",
        "    X, y_and, y_or = generate_truth_table(n)\n",
        "\n",
        "    # Train and evaluate for AND gate\n",
        "    print(f\"\\n=== Testing {n}-input AND gate ===\")\n",
        "    and_perceptron = Perceptron(input_size=n, learning_rate=0.1)\n",
        "    and_converged = and_perceptron.train(X, y_and, max_epochs=100)\n",
        "    and_accuracy = and_perceptron.evaluate(X, y_and)\n",
        "    print(f\"\\nFinal {n}-input AND gate weights: {and_perceptron.weights}\")\n",
        "    print(f\"Final {n}-input AND gate bias: {and_perceptron.bias:.4f}\")\n",
        "    print(f\"AND gate accuracy: {and_accuracy * 100:.2f}%\")\n",
        "\n",
        "    # Train and evaluate for OR gate\n",
        "    print(f\"\\n=== Testing {n}-input OR gate ===\")\n",
        "    or_perceptron = Perceptron(input_size=n, learning_rate=0.1)\n",
        "    or_converged = or_perceptron.train(X, y_or, max_epochs=100)\n",
        "    or_accuracy = or_perceptron.evaluate(X, y_or)\n",
        "    print(f\"\\nFinal {n}-input OR gate weights: {or_perceptron.weights}\")\n",
        "    print(f\"Final {n}-input OR gate bias: {or_perceptron.bias:.4f}\")\n",
        "    print(f\"OR gate accuracy: {or_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Test for n=3 and n=4\n",
        "np.random.seed(42)  # For reproducibility\n",
        "test_perceptron(n=3)\n",
        "test_perceptron(n=4)"
      ]
    }
  ]
}